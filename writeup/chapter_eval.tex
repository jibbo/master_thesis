\chapter{Evaluation}
\label{ch:evaluation}
The goal of this evaluation is to shed light over the success rate of \emph{DevArtist}. Therefore, a similar process to the one described in chapter \ref{sc:preliminaryanalysis} was used and, in fact, it required to install \emph{DevArtistGui} into the device and instruct Monkey Troop on the same subset of apps taken into consideration before. However, this time, every patching solution has been run separately to increase the granularity of the results and the steps executed by the testing tool also tried to emulate a person using the app. In this way, the test was able to check whether a target app was crashing only after the patches were applied.

\subsubsection{Commands for Monkey Troop}
The most visible change in the steps that follow, from the commands executed by Monkey Troop in chapter \ref{sc:preliminaryanalysis}, is represented by the attempt to emulate the usage of the app from a user. However, the capabilities of this automated tester are limited to executing taps at random coordinates of the screen, due to the fact that it does not provide any API to choose where or how to interact with apps. Although this simulation cannot be considered as precise as a real person who taps in the right parts of the screen, it is the best possibility with the available tools.
% of a user wasachieved by generating a random set of coordinates within the resolution of the screen and letting the tester perform those before and after instrumenting a target app.

\begin{enumerate}
	\item{Download an app from the Play Store}
	\item{Install the app on the device(s)}
	\item{Run the app}
	\item{Perform random taps in the app}
	\item{Close the App}
	\item{Start ArtistGUI}
	\item{Instrument the app}
	\item{Run the instrumented App}
	\item{Perform the same random taps in the instrumented app}
	\item{Repeat from 1 with another app from the list}
\end{enumerate}

\subsubsection{The List of Apps}
Following the goal of this work, it was necessary to take into consideration the same set of apps described in chapter \ref{sc:preliminaryanalysis}. It allowed not only to compute how accurate the patching was, but also to check whether \emph{Artist} was suffering of a lower success rate in instrumenting a target app than before my module was applied.   

\section{Results}
Despite the patch for every signature is injected every time a vulnerability is found statically, given the dynamic phase of \emph{DevArtist}, I considered as patched only the logs produced during runtime. Therefore, is it possible that the random taps generated by Monkey Troop couldn't reach all the points of the app where the vulnerable signatures are called, thus showing low numbers in the interested column. Furthermore, all apps that could not be instrumented or crashed after instrumentation (over the total 492) are considered failures. In addition to the data presented in table \ref{tab:evaluation}, the reader should know that \emph{Artist} alone, without any of my code, failed in 33 cases, having a success rate of 85,40\%.
\vspace{1.5cm}
\begin{table}[H]
	\centering
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		Patch & Times Found & Successes & Failures & Unknown State\\
		% \hline
		% Random & 261 & 110 & 111+80 & 151\\
		% \hline
		% rawQuery & 296 & 108 & 45+196 & 161\\
		% \hline
		% Hashing & 308 & 210 & 55+86 & 98\\
		% \hline
		Random & 261 & 110 & 111 & 231\\
		\hline
		rawQuery & 296 & 108 & 45 & 196\\
		\hline
		Hashing & 308 & 210 & 55 & 184\\
		\hline
	\end{tabular}
	% \begin{tabular}{|c|c|}
	% 	\hline
	% 	Patch & Failures\\
	% 	\hline
	% 	Random & 111 \\
	% 	\hline
	% 	rawQuery  & 45 \\
	% 	\hline
	% 	Hashing & 55 \\
	% 	\hline
	% \end{tabular}
	% \newline\newline\newline
	% \begin{tabular}{|c|c|}
	% 	\hline
	% 	Patch & Unknown State\\
	% 	\hline
	% 	Random & 151 \\
	% 	\hline
	% 	rawQuery  & 161 \\
	% 	\hline
	% 	Hashing & 98 \\
	% 	\hline
	% \end{tabular}
	\caption{Results}
	\label{tab:evaluation}
\end{table}
\newpage
\section{Interpretation}
The most interesting result in the data presented in table \ref{tab:evaluation}, is that insecure randomness has been patched in the 42,14\% of the time, showing that changing the random algorithm is more delicate than predicted. The reason behind this finding might be that developers indeed know when to use which algorithm and, in fact, there is a subset of apps which are internally using both \texttt{Random} and \texttt{SecureRandom}, as shown in table \ref{tb:respreliminary} (chapter \ref{ch:investigation}). Patching the \texttt{rawQuery} method is successful, instead, in more than 36,48\% of the times, making instrumentation of the applications crash only 12 times more than \emph{Artist} itself, which is a good result given the amount of code needed for the patch. It is also interesting to find the patch of broken hashing functions to be less risky than imagined. In fact, this patch worked more than 68,18\% of the times, with a failure rate of only 4,5\% more than \emph{Artist} itself (11,2\% vs 6,7\%). This exceptional data suggests that developers need to be more careful when using hashing functions and not only decide to use a secure one, but also to verify its correct usage. It is important to note that, as already stated in the previous section, logs for successful patches are generated at runtime only when the patching code is triggered. Hence, since that code is injected before each vulnerable signature is called, the number of successful patches could have increased if Monkey Troop would have performed a set of taps targeting all the specific executions paths of the apps containing the vulnerable signatures. This is also the main reason behind the unknown state table, all those apps might have been successfully patched or not but until they are manually executed and every one of their execution paths is taken their state cannot be determined.
However, if collected, more than 49,47\% of the apps were successfully patched without decrease in app functionalities.

% It is interesting to note that the easiest patch, the one using \texttt{Random} instead of \texttt{SecureRandom}, was successfully applied only in the 82,15\% of the apps. Moreover, patching the \texttt{rawQuery} method without experiencing crashes or instrumentation failures was successfull 
% The numbers presented above picture a different reality than the one imagined in chapter \ref{ch:devartist}. In fact, the patch with the lowest number of failures is the Hashing one, making it the less "risky" patch.
